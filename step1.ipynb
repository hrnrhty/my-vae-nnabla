{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "step1.ipynb",
      "provenance": [],
      "mount_file_id": "1lrIv6tVOwyaCjUeWIKnzb4KpU-Hxopyu",
      "authorship_tag": "ABX9TyMTxbiCTwbZ2AUaCyzqXvan",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hrnrhty/my-vae-nnabla/blob/main/step1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 1 - VAE の学習 (MNIST)"
      ],
      "metadata": {
        "id": "g-_4I8m7Xx6I"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "最初のステップでは、[nnabla-examples](https://github.com/sony/nnabla-examples) に含まれる VAE (Variational Auto Encoder) をそのまま実行し、学習を行います。学習に用いるデータセットには、手書き数字のデータセットである [MNIST](http://yann.lecun.com/exdb/mnist/) が使用されています。"
      ],
      "metadata": {
        "id": "jr9DvkqQiXVw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "このノートブックでは、学習時間短縮のため GPU アクセラレーションを有効にしています。もし、以降のコードがうまく動かなかった場合は、タブメニューの「ランタイム」 > 「ランタイムのタイプを変更」をクリックし、「ハードウェア アクセラレータ」のドロップダウンメニューで「GPU」が選択されているか確認してください。「GPU」が選択されていなかった場合は、「GPU」を選択して「保存」ボタンをクリックしてください。"
      ],
      "metadata": {
        "id": "_cihoJdJbaY-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Google Drive のマウント"
      ],
      "metadata": {
        "id": "7h_QzBnTYD71"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "学習結果の永続化のため Google Drive をマウントします。"
      ],
      "metadata": {
        "id": "BKaGDUgbYRS_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "vWMARI1jXc6v",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c54468a8-3c40-4605-b066-454304c772ce"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## NNabla のインストール"
      ],
      "metadata": {
        "id": "RKuPn0w3YMSf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sony の [Neural Network Libraries](https://github.com/sony/nnabla) (NNabla) は Google Colab のランタイムにインストールされていないため、インストールします。ここでは、GPU アクセラレーションが使用できるよう、CUDA 版をインストールします。\n",
        "\n",
        "NNabla の依存パッケージの中には既に Google Colab にインストールされているものがあり、NNabla が要求するバージョンと一致していない場合インストール時にエラーが発生することがあります。エラーを無視して先に進んでも問題なく動作することが多いですが、ここではエラー発生を回避します。具体的には、仮想環境を作成し、その中に NNabla をインストールしていきます。\n",
        "\n",
        "通常、仮想環境の作成には Python 3.3 以降標準パッケージに含まれるようになった `venv` が使用されますが、Google Colab ではうまく動作しません。そこで、代わりに [virtualenv](https://virtualenv.pypa.io/en/latest/) をインストールします。`virtualenv` は `venv` の元になったパッケージです。\n",
        "\n",
        "まず、`virtualenv` をインストールし、続いて `venv` という名称の仮想環境を作成します。"
      ],
      "metadata": {
        "id": "XW9kkJtwYpQx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install virtualenv\n",
        "!virtualenv venv"
      ],
      "metadata": {
        "id": "i7fmCf26Sxwz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "349fee39-6743-4f18-eeef-73fbad514ae7"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting virtualenv\n",
            "  Downloading virtualenv-20.13.4-py2.py3-none-any.whl (8.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 8.7 MB 4.4 MB/s \n",
            "\u001b[?25hCollecting distlib<1,>=0.3.1\n",
            "  Downloading distlib-0.3.4-py2.py3-none-any.whl (461 kB)\n",
            "\u001b[K     |████████████████████████████████| 461 kB 44.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: importlib-metadata>=0.12 in /usr/local/lib/python3.7/dist-packages (from virtualenv) (4.11.3)\n",
            "Requirement already satisfied: filelock<4,>=3.2 in /usr/local/lib/python3.7/dist-packages (from virtualenv) (3.6.0)\n",
            "Collecting platformdirs<3,>=2\n",
            "  Downloading platformdirs-2.5.1-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: six<2,>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from virtualenv) (1.15.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.12->virtualenv) (3.10.0.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.12->virtualenv) (3.7.0)\n",
            "Installing collected packages: platformdirs, distlib, virtualenv\n",
            "Successfully installed distlib-0.3.4 platformdirs-2.5.1 virtualenv-20.13.4\n",
            "created virtual environment CPython3.7.12.final.0-64 in 1156ms\n",
            "  creator CPython3Posix(dest=/content/venv, clear=False, no_vcs_ignore=False, global=False)\n",
            "  seeder FromAppData(download=False, pip=bundle, setuptools=bundle, wheel=bundle, via=copy, app_data_dir=/root/.local/share/virtualenv)\n",
            "    added seed packages: pip==22.0.4, setuptools==60.10.0, wheel==0.37.1\n",
            "  activators BashActivator,CShellActivator,FishActivator,NushellActivator,PowerShellActivator,PythonActivator\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "仮想環境をアクティベートし、仮想環境内に NNabla (CUDA版) をインストールします。2022 年 2 月 2 日時点、最新版である v1.25.0 をインストールします。\n",
        "\n",
        "ここで、`!` によるシェルコマンドはサブプロセスとして実行されるため、コマンド実行終了後は状態が維持されないことに注意が必要です。`&&` で連結し1つのコマンドとしてシェルに渡しましょう。2 行に分けてしまうと、2 行目は仮想環境がアクティベートされていない別のサブプロセスになるため、NNabla が仮想環境外にインストールされてしまいます。"
      ],
      "metadata": {
        "id": "G4oyggm2xYQY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!source venv/bin/activate && pip install nnabla-ext-cuda100==1.25.0"
      ],
      "metadata": {
        "id": "GIONkxD1X-KH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4085a859-680f-4abb-caad-bcc0d60a607a"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting nnabla-ext-cuda100==1.25.0\n",
            "  Downloading nnabla_ext_cuda100-1.25.0-cp37-cp37m-manylinux_2_17_x86_64.whl (51.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.1/51.1 MB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: setuptools in ./venv/lib/python3.7/site-packages (from nnabla-ext-cuda100==1.25.0) (60.10.0)\n",
            "Collecting nnabla==1.25.0\n",
            "  Downloading nnabla-1.25.0-cp37-cp37m-manylinux_2_17_x86_64.whl (18.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.1/18.1 MB\u001b[0m \u001b[31m50.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tqdm\n",
            "  Downloading tqdm-4.63.0-py2.py3-none-any.whl (76 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.6/76.6 KB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting configparser\n",
            "  Downloading configparser-5.2.0-py3-none-any.whl (19 kB)\n",
            "Collecting h5py<=3.1.0\n",
            "  Downloading h5py-3.1.0-cp37-cp37m-manylinux1_x86_64.whl (4.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.0/4.0 MB\u001b[0m \u001b[31m65.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pyyaml\n",
            "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m596.3/596.3 KB\u001b[0m \u001b[31m37.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting numpy\n",
            "  Downloading numpy-1.21.5-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (15.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.7/15.7 MB\u001b[0m \u001b[31m30.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting six\n",
            "  Downloading six-1.16.0-py2.py3-none-any.whl (11 kB)\n",
            "Collecting contextlib2\n",
            "  Downloading contextlib2-21.6.0-py2.py3-none-any.whl (13 kB)\n",
            "Collecting protobuf>=3.6\n",
            "  Downloading protobuf-3.19.4-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m48.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting Cython\n",
            "  Downloading Cython-0.29.28-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_24_x86_64.whl (1.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m52.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting imageio\n",
            "  Downloading imageio-2.16.1-py3-none-any.whl (3.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m57.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting boto3\n",
            "  Downloading boto3-1.21.24-py3-none-any.whl (132 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m132.3/132.3 KB\u001b[0m \u001b[31m14.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting scipy\n",
            "  Downloading scipy-1.7.3-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (38.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m38.1/38.1 MB\u001b[0m \u001b[31m12.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pillow\n",
            "  Downloading Pillow-9.0.1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.3/4.3 MB\u001b[0m \u001b[31m65.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting cached-property\n",
            "  Downloading cached_property-1.5.2-py2.py3-none-any.whl (7.6 kB)\n",
            "Collecting s3transfer<0.6.0,>=0.5.0\n",
            "  Downloading s3transfer-0.5.2-py3-none-any.whl (79 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.5/79.5 KB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting botocore<1.25.0,>=1.24.24\n",
            "  Downloading botocore-1.24.24-py3-none-any.whl (8.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.6/8.6 MB\u001b[0m \u001b[31m63.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting jmespath<2.0.0,>=0.7.1\n",
            "  Downloading jmespath-1.0.0-py3-none-any.whl (23 kB)\n",
            "Collecting python-dateutil<3.0.0,>=2.1\n",
            "  Downloading python_dateutil-2.8.2-py2.py3-none-any.whl (247 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m247.7/247.7 KB\u001b[0m \u001b[31m18.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting urllib3<1.27,>=1.25.4\n",
            "  Downloading urllib3-1.26.9-py2.py3-none-any.whl (138 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.0/139.0 KB\u001b[0m \u001b[31m15.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: cached-property, urllib3, tqdm, six, pyyaml, protobuf, pillow, numpy, jmespath, Cython, contextlib2, configparser, scipy, python-dateutil, imageio, h5py, botocore, s3transfer, boto3, nnabla, nnabla-ext-cuda100\n",
            "Successfully installed Cython-0.29.28 boto3-1.21.24 botocore-1.24.24 cached-property-1.5.2 configparser-5.2.0 contextlib2-21.6.0 h5py-3.1.0 imageio-2.16.1 jmespath-1.0.0 nnabla-1.25.0 nnabla-ext-cuda100-1.25.0 numpy-1.21.5 pillow-9.0.1 protobuf-3.19.4 python-dateutil-2.8.2 pyyaml-6.0 s3transfer-0.5.2 scipy-1.7.3 six-1.16.0 tqdm-4.63.0 urllib3-1.26.9\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## nnabla-examples のクローン"
      ],
      "metadata": {
        "id": "2M_gpE9FZOgt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "[nnabla-examples](https://github.com/sony/nnabla-examples) は活発にメンテナンスされており、時々ディレクトリ構成が変更されるため、ここでは Tag v1.25.0 を指定してクローンします。"
      ],
      "metadata": {
        "id": "BzgfgtHTZZae"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!if [ ! -d nnabla-examples ]; then git clone https://github.com/sony/nnabla-examples.git -b v1.25.0 --depth 1; fi"
      ],
      "metadata": {
        "id": "-zcqngp0ZeJH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e4a55f05-67c5-4c8a-fa5f-09caaa363db0"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'nnabla-examples'...\n",
            "remote: Enumerating objects: 1557, done.\u001b[K\n",
            "remote: Counting objects: 100% (1557/1557), done.\u001b[K\n",
            "remote: Compressing objects: 100% (1408/1408), done.\u001b[K\n",
            "remote: Total 1557 (delta 241), reused 884 (delta 82), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (1557/1557), 201.62 MiB | 14.05 MiB/s, done.\n",
            "Resolving deltas: 100% (241/241), done.\n",
            "Note: checking out '03b674a19e8289ce870cd3dfd2a0983d6ef004fc'.\n",
            "\n",
            "You are in 'detached HEAD' state. You can look around, make experimental\n",
            "changes and commit them, and you can discard any commits you make in this\n",
            "state without impacting any branches by performing another checkout.\n",
            "\n",
            "If you want to create a new branch to retain commits you create, you may\n",
            "do so (now or later) by using -b with the checkout command again. Example:\n",
            "\n",
            "  git checkout -b <new-branch-name>\n",
            "\n",
            "Checking out files: 100% (1377/1377), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 学習の実行"
      ],
      "metadata": {
        "id": "mx_UHCeJayV4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "GPU アクセラレーションを有効にするため、`-c cudnn` オプションつきで `vae.py` を実行します。GPU を利用することで、学習にかかる時間が飛躍的に短縮されます。試しに CPU のみで実行したときの学習速度を体感してみたい場合は、`-c cudnn` を削除して実行してください。\n",
        "\n",
        "また、ここでも、仮想環境のアクティベートを忘れないようにしましょう。"
      ],
      "metadata": {
        "id": "TwlC-DXekVLS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!source venv/bin/activate && cd nnabla-examples/image-classification/mnist-collection && python vae.py -c cudnn"
      ],
      "metadata": {
        "id": "PwxFe4axa3is",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "26e3a31f-152c-484c-a8ec-b305aef431fe"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-03-23 09:18:18,571 [nnabla][INFO]: Initializing CPU extension...\n",
            "2022-03-23 09:18:18,973 [nnabla][INFO]: Running in cudnn\n",
            "2022-03-23 09:18:19,586 [nnabla][INFO]: Initializing CUDA extension...\n",
            "2022-03-23 09:18:19,649 [nnabla][INFO]: Initializing cuDNN extension...\n",
            "2022-03-23 09:18:19,650 [nnabla][INFO]: DataSource with shuffle(True)\n",
            "2022-03-23 09:18:19,650 [nnabla][INFO]: Getting label data from http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz.\n",
            "train-labels-idx1-ubyte.gz: 100% 28.2k/28.2k [00:00<00:00, 18.6MB/s]\n",
            "2022-03-23 09:18:19,724 [nnabla][INFO]: Getting label data done.\n",
            "2022-03-23 09:18:19,724 [nnabla][INFO]: Getting image data from http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz.\n",
            "train-images-idx3-ubyte.gz: 100% 9.45M/9.45M [00:00<00:00, 73.1MB/s]\n",
            "2022-03-23 09:18:20,202 [nnabla][INFO]: Getting image data done.\n",
            "2022-03-23 09:18:20,205 [nnabla][INFO]: Using DataIterator\n",
            "2022-03-23 09:18:20,207 [nnabla][INFO]: DataSource with shuffle(True)\n",
            "2022-03-23 09:18:20,207 [nnabla][INFO]: Getting label data from http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz.\n",
            "t10k-labels-idx1-ubyte.gz: 100% 4.44k/4.44k [00:00<00:00, 9.10MB/s]\n",
            "2022-03-23 09:18:20,260 [nnabla][INFO]: Getting label data done.\n",
            "2022-03-23 09:18:20,261 [nnabla][INFO]: Getting image data from http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz.\n",
            "t10k-images-idx3-ubyte.gz: 100% 1.57M/1.57M [00:00<00:00, 19.7MB/s]\n",
            "2022-03-23 09:18:20,451 [nnabla][INFO]: Getting image data done.\n",
            "2022-03-23 09:18:20,452 [nnabla][INFO]: Using DataIterator\n",
            "2022-03-23 09:18:22,449 [nnabla][INFO]: Saving tmp.monitor.vae/lenet_resultEpoch0.nnp as nnp\n",
            "2022-03-23 09:18:22,449 [nnabla][INFO]: Saving <_io.StringIO object at 0x7fecc6c6ea50> as prototxt\n",
            "2022-03-23 09:18:22,573 [nnabla][INFO]: Parameter save (.protobuf): <_io.BytesIO object at 0x7fec8d633590>\n",
            "2022-03-23 09:18:22,584 [nnabla][INFO]: Model file is saved as (.nnp): tmp.monitor.vae/lenet_resultEpoch0.nnp\n",
            "2022-03-23 09:18:26,821 [nnabla][INFO]: iter=599 {Training loss}=170.4720458984375\n",
            "2022-03-23 09:18:26,822 [nnabla][INFO]: iter=599 {Test loss}=157.71517944335938\n",
            "2022-03-23 09:18:26,822 [nnabla][INFO]: iter=599 {Elapsed time}=4.390463352203369[sec/600iter] 4.390463352203369[sec]\n",
            "2022-03-23 09:18:29,242 [nnabla][INFO]: iter=1199 {Training loss}=120.98400115966797\n",
            "2022-03-23 09:18:29,242 [nnabla][INFO]: iter=1199 {Test loss}=106.66517639160156\n",
            "2022-03-23 09:18:29,243 [nnabla][INFO]: iter=1199 {Elapsed time}=2.4204187393188477[sec/600iter] 6.810882091522217[sec]\n",
            "2022-03-23 09:18:31,659 [nnabla][INFO]: iter=1799 {Training loss}=108.28484344482422\n",
            "2022-03-23 09:18:31,659 [nnabla][INFO]: iter=1799 {Test loss}=94.92371368408203\n",
            "2022-03-23 09:18:31,660 [nnabla][INFO]: iter=1799 {Elapsed time}=2.41703200340271[sec/600iter] 9.227914094924927[sec]\n",
            "2022-03-23 09:18:34,067 [nnabla][INFO]: iter=2399 {Training loss}=102.45285034179688\n",
            "2022-03-23 09:18:34,067 [nnabla][INFO]: iter=2399 {Test loss}=89.61978149414062\n",
            "2022-03-23 09:18:34,068 [nnabla][INFO]: iter=2399 {Elapsed time}=2.4079091548919678[sec/600iter] 11.635823249816895[sec]\n",
            "2022-03-23 09:18:36,487 [nnabla][INFO]: iter=2999 {Training loss}=98.91474914550781\n",
            "2022-03-23 09:18:36,488 [nnabla][INFO]: iter=2999 {Test loss}=86.4316177368164\n",
            "2022-03-23 09:18:36,488 [nnabla][INFO]: iter=2999 {Elapsed time}=2.42049241065979[sec/600iter] 14.056315660476685[sec]\n",
            "2022-03-23 09:18:38,908 [nnabla][INFO]: iter=3599 {Training loss}=96.35784149169922\n",
            "2022-03-23 09:18:38,908 [nnabla][INFO]: iter=3599 {Test loss}=84.17122650146484\n",
            "2022-03-23 09:18:38,908 [nnabla][INFO]: iter=3599 {Elapsed time}=2.420403480529785[sec/600iter] 16.47671914100647[sec]\n",
            "2022-03-23 09:18:41,333 [nnabla][INFO]: iter=4199 {Training loss}=94.59732818603516\n",
            "2022-03-23 09:18:41,334 [nnabla][INFO]: iter=4199 {Test loss}=82.58406066894531\n",
            "2022-03-23 09:18:41,334 [nnabla][INFO]: iter=4199 {Elapsed time}=2.425589084625244[sec/600iter] 18.902308225631714[sec]\n",
            "2022-03-23 09:18:43,754 [nnabla][INFO]: iter=4799 {Training loss}=93.1684799194336\n",
            "2022-03-23 09:18:43,754 [nnabla][INFO]: iter=4799 {Test loss}=81.3510971069336\n",
            "2022-03-23 09:18:43,754 [nnabla][INFO]: iter=4799 {Elapsed time}=2.4203684329986572[sec/600iter] 21.32267665863037[sec]\n",
            "2022-03-23 09:18:46,167 [nnabla][INFO]: iter=5399 {Training loss}=91.98812866210938\n",
            "2022-03-23 09:18:46,168 [nnabla][INFO]: iter=5399 {Test loss}=80.33334350585938\n",
            "2022-03-23 09:18:46,168 [nnabla][INFO]: iter=5399 {Elapsed time}=2.413661479949951[sec/600iter] 23.736338138580322[sec]\n",
            "2022-03-23 09:18:48,602 [nnabla][INFO]: iter=5999 {Training loss}=91.00794219970703\n",
            "2022-03-23 09:18:48,602 [nnabla][INFO]: iter=5999 {Test loss}=79.5107421875\n",
            "2022-03-23 09:18:48,603 [nnabla][INFO]: iter=5999 {Elapsed time}=2.4344825744628906[sec/600iter] 26.170820713043213[sec]\n",
            "2022-03-23 09:18:51,032 [nnabla][INFO]: iter=6599 {Training loss}=90.27079772949219\n",
            "2022-03-23 09:18:51,032 [nnabla][INFO]: iter=6599 {Test loss}=78.92071533203125\n",
            "2022-03-23 09:18:51,032 [nnabla][INFO]: iter=6599 {Elapsed time}=2.429840326309204[sec/600iter] 28.600661039352417[sec]\n",
            "2022-03-23 09:18:53,460 [nnabla][INFO]: iter=7199 {Training loss}=89.56714630126953\n",
            "2022-03-23 09:18:53,460 [nnabla][INFO]: iter=7199 {Test loss}=78.34869384765625\n",
            "2022-03-23 09:18:53,460 [nnabla][INFO]: iter=7199 {Elapsed time}=2.428072690963745[sec/600iter] 31.028733730316162[sec]\n",
            "2022-03-23 09:18:55,896 [nnabla][INFO]: iter=7799 {Training loss}=88.89962005615234\n",
            "2022-03-23 09:18:55,896 [nnabla][INFO]: iter=7799 {Test loss}=77.80875396728516\n",
            "2022-03-23 09:18:55,897 [nnabla][INFO]: iter=7799 {Elapsed time}=2.43619966506958[sec/600iter] 33.46493339538574[sec]\n",
            "2022-03-23 09:18:58,329 [nnabla][INFO]: iter=8399 {Training loss}=88.42329406738281\n",
            "2022-03-23 09:18:58,330 [nnabla][INFO]: iter=8399 {Test loss}=77.42537689208984\n",
            "2022-03-23 09:18:58,330 [nnabla][INFO]: iter=8399 {Elapsed time}=2.433647871017456[sec/600iter] 35.8985812664032[sec]\n",
            "2022-03-23 09:19:00,756 [nnabla][INFO]: iter=8999 {Training loss}=87.93148803710938\n",
            "2022-03-23 09:19:00,757 [nnabla][INFO]: iter=8999 {Test loss}=77.04820251464844\n",
            "2022-03-23 09:19:00,757 [nnabla][INFO]: iter=8999 {Elapsed time}=2.4267144203186035[sec/600iter] 38.3252956867218[sec]\n",
            "2022-03-23 09:19:03,225 [nnabla][INFO]: iter=9599 {Training loss}=87.39730834960938\n",
            "2022-03-23 09:19:03,225 [nnabla][INFO]: iter=9599 {Test loss}=76.60269165039062\n",
            "2022-03-23 09:19:03,225 [nnabla][INFO]: iter=9599 {Elapsed time}=2.468410015106201[sec/600iter] 40.793705701828[sec]\n",
            "2022-03-23 09:19:05,640 [nnabla][INFO]: iter=10199 {Training loss}=87.05500030517578\n",
            "2022-03-23 09:19:05,641 [nnabla][INFO]: iter=10199 {Test loss}=76.3577880859375\n",
            "2022-03-23 09:19:05,641 [nnabla][INFO]: iter=10199 {Elapsed time}=2.415915012359619[sec/600iter] 43.20962071418762[sec]\n",
            "2022-03-23 09:19:08,063 [nnabla][INFO]: iter=10799 {Training loss}=86.68708038330078\n",
            "2022-03-23 09:19:08,064 [nnabla][INFO]: iter=10799 {Test loss}=76.078857421875\n",
            "2022-03-23 09:19:08,064 [nnabla][INFO]: iter=10799 {Elapsed time}=2.4224166870117188[sec/600iter] 45.63203740119934[sec]\n",
            "2022-03-23 09:19:10,491 [nnabla][INFO]: iter=11399 {Training loss}=86.35936737060547\n",
            "2022-03-23 09:19:10,492 [nnabla][INFO]: iter=11399 {Test loss}=75.82620239257812\n",
            "2022-03-23 09:19:10,492 [nnabla][INFO]: iter=11399 {Elapsed time}=2.428067207336426[sec/600iter] 48.06010460853577[sec]\n",
            "2022-03-23 09:19:12,920 [nnabla][INFO]: iter=11999 {Training loss}=86.05546569824219\n",
            "2022-03-23 09:19:12,920 [nnabla][INFO]: iter=11999 {Test loss}=75.62776947021484\n",
            "2022-03-23 09:19:12,921 [nnabla][INFO]: iter=11999 {Elapsed time}=2.4286515712738037[sec/600iter] 50.48875617980957[sec]\n",
            "2022-03-23 09:19:15,336 [nnabla][INFO]: iter=12599 {Training loss}=85.6660385131836\n",
            "2022-03-23 09:19:15,337 [nnabla][INFO]: iter=12599 {Test loss}=75.33383178710938\n",
            "2022-03-23 09:19:15,337 [nnabla][INFO]: iter=12599 {Elapsed time}=2.4168171882629395[sec/600iter] 52.90557336807251[sec]\n",
            "2022-03-23 09:19:17,760 [nnabla][INFO]: iter=13199 {Training loss}=85.41437530517578\n",
            "2022-03-23 09:19:17,760 [nnabla][INFO]: iter=13199 {Test loss}=75.18379211425781\n",
            "2022-03-23 09:19:17,761 [nnabla][INFO]: iter=13199 {Elapsed time}=2.423330068588257[sec/600iter] 55.32890343666077[sec]\n",
            "2022-03-23 09:19:20,173 [nnabla][INFO]: iter=13799 {Training loss}=85.12703704833984\n",
            "2022-03-23 09:19:20,173 [nnabla][INFO]: iter=13799 {Test loss}=74.9287109375\n",
            "2022-03-23 09:19:20,174 [nnabla][INFO]: iter=13799 {Elapsed time}=2.4129176139831543[sec/600iter] 57.74182105064392[sec]\n",
            "2022-03-23 09:19:22,592 [nnabla][INFO]: iter=14399 {Training loss}=84.9292221069336\n",
            "2022-03-23 09:19:22,593 [nnabla][INFO]: iter=14399 {Test loss}=74.79067993164062\n",
            "2022-03-23 09:19:22,594 [nnabla][INFO]: iter=14399 {Elapsed time}=2.420030355453491[sec/600iter] 60.16185140609741[sec]\n",
            "2022-03-23 09:19:25,005 [nnabla][INFO]: iter=14999 {Training loss}=84.7291488647461\n",
            "2022-03-23 09:19:25,005 [nnabla][INFO]: iter=14999 {Test loss}=74.63629150390625\n",
            "2022-03-23 09:19:25,006 [nnabla][INFO]: iter=14999 {Elapsed time}=2.411975860595703[sec/600iter] 62.573827266693115[sec]\n",
            "2022-03-23 09:19:27,412 [nnabla][INFO]: iter=15599 {Training loss}=84.47586059570312\n",
            "2022-03-23 09:19:27,413 [nnabla][INFO]: iter=15599 {Test loss}=74.52255249023438\n",
            "2022-03-23 09:19:27,413 [nnabla][INFO]: iter=15599 {Elapsed time}=2.4076449871063232[sec/600iter] 64.98147225379944[sec]\n",
            "2022-03-23 09:19:29,840 [nnabla][INFO]: iter=16199 {Training loss}=84.22557067871094\n",
            "2022-03-23 09:19:29,840 [nnabla][INFO]: iter=16199 {Test loss}=74.29286193847656\n",
            "2022-03-23 09:19:29,841 [nnabla][INFO]: iter=16199 {Elapsed time}=2.427326202392578[sec/600iter] 67.40879845619202[sec]\n",
            "2022-03-23 09:19:32,255 [nnabla][INFO]: iter=16799 {Training loss}=84.11967468261719\n",
            "2022-03-23 09:19:32,256 [nnabla][INFO]: iter=16799 {Test loss}=74.2484130859375\n",
            "2022-03-23 09:19:32,256 [nnabla][INFO]: iter=16799 {Elapsed time}=2.4156582355499268[sec/600iter] 69.82445669174194[sec]\n",
            "2022-03-23 09:19:34,672 [nnabla][INFO]: iter=17399 {Training loss}=83.83422088623047\n",
            "2022-03-23 09:19:34,673 [nnabla][INFO]: iter=17399 {Test loss}=74.053466796875\n",
            "2022-03-23 09:19:34,673 [nnabla][INFO]: iter=17399 {Elapsed time}=2.4169695377349854[sec/600iter] 72.24142622947693[sec]\n",
            "2022-03-23 09:19:37,099 [nnabla][INFO]: iter=17999 {Training loss}=83.66312408447266\n",
            "2022-03-23 09:19:37,099 [nnabla][INFO]: iter=17999 {Test loss}=73.9495849609375\n",
            "2022-03-23 09:19:37,100 [nnabla][INFO]: iter=17999 {Elapsed time}=2.4263625144958496[sec/600iter] 74.66778874397278[sec]\n",
            "2022-03-23 09:19:39,517 [nnabla][INFO]: iter=18599 {Training loss}=83.47148132324219\n",
            "2022-03-23 09:19:39,517 [nnabla][INFO]: iter=18599 {Test loss}=73.82527923583984\n",
            "2022-03-23 09:19:39,517 [nnabla][INFO]: iter=18599 {Elapsed time}=2.4178900718688965[sec/600iter] 77.08567881584167[sec]\n",
            "2022-03-23 09:19:41,946 [nnabla][INFO]: iter=19199 {Training loss}=83.2358627319336\n",
            "2022-03-23 09:19:41,947 [nnabla][INFO]: iter=19199 {Test loss}=73.63948059082031\n",
            "2022-03-23 09:19:41,947 [nnabla][INFO]: iter=19199 {Elapsed time}=2.429860830307007[sec/600iter] 79.51553964614868[sec]\n",
            "2022-03-23 09:19:44,358 [nnabla][INFO]: iter=19799 {Training loss}=83.18096160888672\n",
            "2022-03-23 09:19:44,359 [nnabla][INFO]: iter=19799 {Test loss}=73.63070678710938\n",
            "2022-03-23 09:19:44,359 [nnabla][INFO]: iter=19799 {Elapsed time}=2.41194748878479[sec/600iter] 81.92748713493347[sec]\n",
            "2022-03-23 09:19:46,766 [nnabla][INFO]: iter=20399 {Training loss}=82.94538879394531\n",
            "2022-03-23 09:19:46,767 [nnabla][INFO]: iter=20399 {Test loss}=73.47245025634766\n",
            "2022-03-23 09:19:46,767 [nnabla][INFO]: iter=20399 {Elapsed time}=2.4077093601226807[sec/600iter] 84.33519649505615[sec]\n",
            "2022-03-23 09:19:49,182 [nnabla][INFO]: iter=20999 {Training loss}=82.73184967041016\n",
            "2022-03-23 09:19:49,183 [nnabla][INFO]: iter=20999 {Test loss}=73.34789276123047\n",
            "2022-03-23 09:19:49,184 [nnabla][INFO]: iter=20999 {Elapsed time}=2.4166605472564697[sec/600iter] 86.75185704231262[sec]\n",
            "2022-03-23 09:19:51,602 [nnabla][INFO]: iter=21599 {Training loss}=82.64778900146484\n",
            "2022-03-23 09:19:51,602 [nnabla][INFO]: iter=21599 {Test loss}=73.30502319335938\n",
            "2022-03-23 09:19:51,603 [nnabla][INFO]: iter=21599 {Elapsed time}=2.419072151184082[sec/600iter] 89.1709291934967[sec]\n",
            "2022-03-23 09:19:54,023 [nnabla][INFO]: iter=22199 {Training loss}=82.52313995361328\n",
            "2022-03-23 09:19:54,023 [nnabla][INFO]: iter=22199 {Test loss}=73.19293212890625\n",
            "2022-03-23 09:19:54,024 [nnabla][INFO]: iter=22199 {Elapsed time}=2.4209935665130615[sec/600iter] 91.59192276000977[sec]\n",
            "2022-03-23 09:19:56,438 [nnabla][INFO]: iter=22799 {Training loss}=82.39077758789062\n",
            "2022-03-23 09:19:56,439 [nnabla][INFO]: iter=22799 {Test loss}=73.13481140136719\n",
            "2022-03-23 09:19:56,439 [nnabla][INFO]: iter=22799 {Elapsed time}=2.4155900478363037[sec/600iter] 94.00751280784607[sec]\n",
            "2022-03-23 09:19:58,841 [nnabla][INFO]: iter=23399 {Training loss}=82.16697692871094\n",
            "2022-03-23 09:19:58,842 [nnabla][INFO]: iter=23399 {Test loss}=73.01614379882812\n",
            "2022-03-23 09:19:58,843 [nnabla][INFO]: iter=23399 {Elapsed time}=2.403259515762329[sec/600iter] 96.4107723236084[sec]\n",
            "2022-03-23 09:20:01,260 [nnabla][INFO]: iter=23999 {Training loss}=82.0849380493164\n",
            "2022-03-23 09:20:01,261 [nnabla][INFO]: iter=23999 {Test loss}=72.97813415527344\n",
            "2022-03-23 09:20:01,261 [nnabla][INFO]: iter=23999 {Elapsed time}=2.4182937145233154[sec/600iter] 98.82906603813171[sec]\n",
            "2022-03-23 09:20:03,688 [nnabla][INFO]: iter=24599 {Training loss}=81.90286254882812\n",
            "2022-03-23 09:20:03,689 [nnabla][INFO]: iter=24599 {Test loss}=72.85022735595703\n",
            "2022-03-23 09:20:03,689 [nnabla][INFO]: iter=24599 {Elapsed time}=2.4285190105438232[sec/600iter] 101.25758504867554[sec]\n",
            "2022-03-23 09:20:06,106 [nnabla][INFO]: iter=25199 {Training loss}=81.79405212402344\n",
            "2022-03-23 09:20:06,106 [nnabla][INFO]: iter=25199 {Test loss}=72.80015563964844\n",
            "2022-03-23 09:20:06,107 [nnabla][INFO]: iter=25199 {Elapsed time}=2.4173054695129395[sec/600iter] 103.67489051818848[sec]\n",
            "2022-03-23 09:20:08,521 [nnabla][INFO]: iter=25799 {Training loss}=81.64242553710938\n",
            "2022-03-23 09:20:08,521 [nnabla][INFO]: iter=25799 {Test loss}=72.6910171508789\n",
            "2022-03-23 09:20:08,521 [nnabla][INFO]: iter=25799 {Elapsed time}=2.4147934913635254[sec/600iter] 106.089684009552[sec]\n",
            "2022-03-23 09:20:10,947 [nnabla][INFO]: iter=26399 {Training loss}=81.51594543457031\n",
            "2022-03-23 09:20:10,947 [nnabla][INFO]: iter=26399 {Test loss}=72.64999389648438\n",
            "2022-03-23 09:20:10,948 [nnabla][INFO]: iter=26399 {Elapsed time}=2.426103353500366[sec/600iter] 108.51578736305237[sec]\n",
            "2022-03-23 09:20:13,372 [nnabla][INFO]: iter=26999 {Training loss}=81.43456268310547\n",
            "2022-03-23 09:20:13,372 [nnabla][INFO]: iter=26999 {Test loss}=72.58064270019531\n",
            "2022-03-23 09:20:13,373 [nnabla][INFO]: iter=26999 {Elapsed time}=2.4251232147216797[sec/600iter] 110.94091057777405[sec]\n",
            "2022-03-23 09:20:15,804 [nnabla][INFO]: iter=27599 {Training loss}=81.25874328613281\n",
            "2022-03-23 09:20:15,805 [nnabla][INFO]: iter=27599 {Test loss}=72.4959487915039\n",
            "2022-03-23 09:20:15,805 [nnabla][INFO]: iter=27599 {Elapsed time}=2.4322004318237305[sec/600iter] 113.37311100959778[sec]\n",
            "2022-03-23 09:20:18,221 [nnabla][INFO]: iter=28199 {Training loss}=81.1573715209961\n",
            "2022-03-23 09:20:18,222 [nnabla][INFO]: iter=28199 {Test loss}=72.44136810302734\n",
            "2022-03-23 09:20:18,222 [nnabla][INFO]: iter=28199 {Elapsed time}=2.4168753623962402[sec/600iter] 115.78998637199402[sec]\n",
            "2022-03-23 09:20:20,648 [nnabla][INFO]: iter=28799 {Training loss}=81.07597351074219\n",
            "2022-03-23 09:20:20,649 [nnabla][INFO]: iter=28799 {Test loss}=72.36505889892578\n",
            "2022-03-23 09:20:20,649 [nnabla][INFO]: iter=28799 {Elapsed time}=2.4274673461914062[sec/600iter] 118.21745371818542[sec]\n",
            "2022-03-23 09:20:23,070 [nnabla][INFO]: iter=29399 {Training loss}=80.99644470214844\n",
            "2022-03-23 09:20:23,071 [nnabla][INFO]: iter=29399 {Test loss}=72.3385009765625\n",
            "2022-03-23 09:20:23,071 [nnabla][INFO]: iter=29399 {Elapsed time}=2.4220759868621826[sec/600iter] 120.63952970504761[sec]\n",
            "2022-03-23 09:20:25,492 [nnabla][INFO]: iter=29999 {Training loss}=80.83182525634766\n",
            "2022-03-23 09:20:25,492 [nnabla][INFO]: iter=29999 {Test loss}=72.22962188720703\n",
            "2022-03-23 09:20:25,493 [nnabla][INFO]: iter=29999 {Elapsed time}=2.4212653636932373[sec/600iter] 123.06079506874084[sec]\n",
            "2022-03-23 09:20:27,913 [nnabla][INFO]: iter=30599 {Training loss}=80.74264526367188\n",
            "2022-03-23 09:20:27,913 [nnabla][INFO]: iter=30599 {Test loss}=72.18865966796875\n",
            "2022-03-23 09:20:27,913 [nnabla][INFO]: iter=30599 {Elapsed time}=2.4209275245666504[sec/600iter] 125.4817225933075[sec]\n",
            "2022-03-23 09:20:30,334 [nnabla][INFO]: iter=31199 {Training loss}=80.61187744140625\n",
            "2022-03-23 09:20:30,335 [nnabla][INFO]: iter=31199 {Test loss}=72.14054870605469\n",
            "2022-03-23 09:20:30,335 [nnabla][INFO]: iter=31199 {Elapsed time}=2.4215986728668213[sec/600iter] 127.90332126617432[sec]\n",
            "2022-03-23 09:20:32,757 [nnabla][INFO]: iter=31799 {Training loss}=80.57259368896484\n",
            "2022-03-23 09:20:32,757 [nnabla][INFO]: iter=31799 {Test loss}=72.15373992919922\n",
            "2022-03-23 09:20:32,757 [nnabla][INFO]: iter=31799 {Elapsed time}=2.42240834236145[sec/600iter] 130.32572960853577[sec]\n",
            "2022-03-23 09:20:35,180 [nnabla][INFO]: iter=32399 {Training loss}=80.41498565673828\n",
            "2022-03-23 09:20:35,180 [nnabla][INFO]: iter=32399 {Test loss}=72.04591369628906\n",
            "2022-03-23 09:20:35,181 [nnabla][INFO]: iter=32399 {Elapsed time}=2.423191547393799[sec/600iter] 132.74892115592957[sec]\n",
            "2022-03-23 09:20:37,606 [nnabla][INFO]: iter=32999 {Training loss}=80.33722686767578\n",
            "2022-03-23 09:20:37,607 [nnabla][INFO]: iter=32999 {Test loss}=71.97328186035156\n",
            "2022-03-23 09:20:37,607 [nnabla][INFO]: iter=32999 {Elapsed time}=2.426048994064331[sec/600iter] 135.1749701499939[sec]\n",
            "2022-03-23 09:20:40,034 [nnabla][INFO]: iter=33599 {Training loss}=80.21410369873047\n",
            "2022-03-23 09:20:40,035 [nnabla][INFO]: iter=33599 {Test loss}=71.93240356445312\n",
            "2022-03-23 09:20:40,035 [nnabla][INFO]: iter=33599 {Elapsed time}=2.4280264377593994[sec/600iter] 137.6029965877533[sec]\n",
            "2022-03-23 09:20:42,472 [nnabla][INFO]: iter=34199 {Training loss}=80.1463394165039\n",
            "2022-03-23 09:20:42,472 [nnabla][INFO]: iter=34199 {Test loss}=71.90510559082031\n",
            "2022-03-23 09:20:42,473 [nnabla][INFO]: iter=34199 {Elapsed time}=2.4379124641418457[sec/600iter] 140.04090905189514[sec]\n",
            "2022-03-23 09:20:44,899 [nnabla][INFO]: iter=34799 {Training loss}=80.10317993164062\n",
            "2022-03-23 09:20:44,900 [nnabla][INFO]: iter=34799 {Test loss}=71.9000473022461\n",
            "2022-03-23 09:20:44,900 [nnabla][INFO]: iter=34799 {Elapsed time}=2.4272170066833496[sec/600iter] 142.4681260585785[sec]\n",
            "2022-03-23 09:20:47,321 [nnabla][INFO]: iter=35399 {Training loss}=79.92955780029297\n",
            "2022-03-23 09:20:47,322 [nnabla][INFO]: iter=35399 {Test loss}=71.78028869628906\n",
            "2022-03-23 09:20:47,322 [nnabla][INFO]: iter=35399 {Elapsed time}=2.4225375652313232[sec/600iter] 144.89066362380981[sec]\n",
            "2022-03-23 09:20:49,741 [nnabla][INFO]: iter=35999 {Training loss}=79.86575317382812\n",
            "2022-03-23 09:20:49,742 [nnabla][INFO]: iter=35999 {Test loss}=71.79303741455078\n",
            "2022-03-23 09:20:49,742 [nnabla][INFO]: iter=35999 {Elapsed time}=2.419915199279785[sec/600iter] 147.3105788230896[sec]\n",
            "2022-03-23 09:20:52,173 [nnabla][INFO]: iter=36599 {Training loss}=79.74205780029297\n",
            "2022-03-23 09:20:52,173 [nnabla][INFO]: iter=36599 {Test loss}=71.73492431640625\n",
            "2022-03-23 09:20:52,173 [nnabla][INFO]: iter=36599 {Elapsed time}=2.431077480316162[sec/600iter] 149.74165630340576[sec]\n",
            "2022-03-23 09:20:54,605 [nnabla][INFO]: iter=37199 {Training loss}=79.67666625976562\n",
            "2022-03-23 09:20:54,605 [nnabla][INFO]: iter=37199 {Test loss}=71.67591857910156\n",
            "2022-03-23 09:20:54,605 [nnabla][INFO]: iter=37199 {Elapsed time}=2.4320507049560547[sec/600iter] 152.17370700836182[sec]\n",
            "2022-03-23 09:20:57,031 [nnabla][INFO]: iter=37799 {Training loss}=79.57027435302734\n",
            "2022-03-23 09:20:57,032 [nnabla][INFO]: iter=37799 {Test loss}=71.64326477050781\n",
            "2022-03-23 09:20:57,032 [nnabla][INFO]: iter=37799 {Elapsed time}=2.426279306411743[sec/600iter] 154.59998631477356[sec]\n",
            "2022-03-23 09:20:59,450 [nnabla][INFO]: iter=38399 {Training loss}=79.52847290039062\n",
            "2022-03-23 09:20:59,450 [nnabla][INFO]: iter=38399 {Test loss}=71.64059448242188\n",
            "2022-03-23 09:20:59,450 [nnabla][INFO]: iter=38399 {Elapsed time}=2.418651819229126[sec/600iter] 157.01863813400269[sec]\n",
            "2022-03-23 09:21:01,877 [nnabla][INFO]: iter=38999 {Training loss}=79.44144439697266\n",
            "2022-03-23 09:21:01,877 [nnabla][INFO]: iter=38999 {Test loss}=71.5877685546875\n",
            "2022-03-23 09:21:01,878 [nnabla][INFO]: iter=38999 {Elapsed time}=2.427232265472412[sec/600iter] 159.4458703994751[sec]\n",
            "2022-03-23 09:21:04,289 [nnabla][INFO]: iter=39599 {Training loss}=79.29772186279297\n",
            "2022-03-23 09:21:04,289 [nnabla][INFO]: iter=39599 {Test loss}=71.51118469238281\n",
            "2022-03-23 09:21:04,289 [nnabla][INFO]: iter=39599 {Elapsed time}=2.4118473529815674[sec/600iter] 161.85771775245667[sec]\n",
            "2022-03-23 09:21:06,707 [nnabla][INFO]: iter=40199 {Training loss}=79.24439239501953\n",
            "2022-03-23 09:21:06,708 [nnabla][INFO]: iter=40199 {Test loss}=71.5074234008789\n",
            "2022-03-23 09:21:06,708 [nnabla][INFO]: iter=40199 {Elapsed time}=2.4188899993896484[sec/600iter] 164.2766077518463[sec]\n",
            "2022-03-23 09:21:09,128 [nnabla][INFO]: iter=40799 {Training loss}=79.15150451660156\n",
            "2022-03-23 09:21:09,129 [nnabla][INFO]: iter=40799 {Test loss}=71.47464752197266\n",
            "2022-03-23 09:21:09,129 [nnabla][INFO]: iter=40799 {Elapsed time}=2.4209327697753906[sec/600iter] 166.6975405216217[sec]\n",
            "2022-03-23 09:21:11,551 [nnabla][INFO]: iter=41399 {Training loss}=79.07954406738281\n",
            "2022-03-23 09:21:11,552 [nnabla][INFO]: iter=41399 {Test loss}=71.44757080078125\n",
            "2022-03-23 09:21:11,552 [nnabla][INFO]: iter=41399 {Elapsed time}=2.4229207038879395[sec/600iter] 169.12046122550964[sec]\n",
            "2022-03-23 09:21:13,978 [nnabla][INFO]: iter=41999 {Training loss}=78.97467803955078\n",
            "2022-03-23 09:21:13,979 [nnabla][INFO]: iter=41999 {Test loss}=71.38458251953125\n",
            "2022-03-23 09:21:13,979 [nnabla][INFO]: iter=41999 {Elapsed time}=2.4265220165252686[sec/600iter] 171.5469832420349[sec]\n",
            "2022-03-23 09:21:16,401 [nnabla][INFO]: iter=42599 {Training loss}=79.01631164550781\n",
            "2022-03-23 09:21:16,401 [nnabla][INFO]: iter=42599 {Test loss}=71.43987274169922\n",
            "2022-03-23 09:21:16,402 [nnabla][INFO]: iter=42599 {Elapsed time}=2.4227640628814697[sec/600iter] 173.96974730491638[sec]\n",
            "2022-03-23 09:21:18,823 [nnabla][INFO]: iter=43199 {Training loss}=78.86003112792969\n",
            "2022-03-23 09:21:18,824 [nnabla][INFO]: iter=43199 {Test loss}=71.36763763427734\n",
            "2022-03-23 09:21:18,824 [nnabla][INFO]: iter=43199 {Elapsed time}=2.422349691390991[sec/600iter] 176.39209699630737[sec]\n",
            "2022-03-23 09:21:21,248 [nnabla][INFO]: iter=43799 {Training loss}=78.76502227783203\n",
            "2022-03-23 09:21:21,249 [nnabla][INFO]: iter=43799 {Test loss}=71.3224105834961\n",
            "2022-03-23 09:21:21,250 [nnabla][INFO]: iter=43799 {Elapsed time}=2.425680637359619[sec/600iter] 178.817777633667[sec]\n",
            "2022-03-23 09:21:23,671 [nnabla][INFO]: iter=44399 {Training loss}=78.70696258544922\n",
            "2022-03-23 09:21:23,672 [nnabla][INFO]: iter=44399 {Test loss}=71.31034088134766\n",
            "2022-03-23 09:21:23,672 [nnabla][INFO]: iter=44399 {Elapsed time}=2.4225826263427734[sec/600iter] 181.24036026000977[sec]\n",
            "2022-03-23 09:21:26,092 [nnabla][INFO]: iter=44999 {Training loss}=78.58879852294922\n",
            "2022-03-23 09:21:26,093 [nnabla][INFO]: iter=44999 {Test loss}=71.2432632446289\n",
            "2022-03-23 09:21:26,093 [nnabla][INFO]: iter=44999 {Elapsed time}=2.4205896854400635[sec/600iter] 183.66094994544983[sec]\n",
            "2022-03-23 09:21:28,525 [nnabla][INFO]: iter=45599 {Training loss}=78.55940246582031\n",
            "2022-03-23 09:21:28,525 [nnabla][INFO]: iter=45599 {Test loss}=71.23079681396484\n",
            "2022-03-23 09:21:28,526 [nnabla][INFO]: iter=45599 {Elapsed time}=2.433009386062622[sec/600iter] 186.09395933151245[sec]\n",
            "2022-03-23 09:21:30,951 [nnabla][INFO]: iter=46199 {Training loss}=78.48216247558594\n",
            "2022-03-23 09:21:30,952 [nnabla][INFO]: iter=46199 {Test loss}=71.18976593017578\n",
            "2022-03-23 09:21:30,952 [nnabla][INFO]: iter=46199 {Elapsed time}=2.4260127544403076[sec/600iter] 188.51997208595276[sec]\n",
            "2022-03-23 09:21:33,370 [nnabla][INFO]: iter=46799 {Training loss}=78.37931060791016\n",
            "2022-03-23 09:21:33,371 [nnabla][INFO]: iter=46799 {Test loss}=71.15441131591797\n",
            "2022-03-23 09:21:33,371 [nnabla][INFO]: iter=46799 {Elapsed time}=2.419412851333618[sec/600iter] 190.93938493728638[sec]\n",
            "2022-03-23 09:21:35,794 [nnabla][INFO]: iter=47399 {Training loss}=78.31867980957031\n",
            "2022-03-23 09:21:35,795 [nnabla][INFO]: iter=47399 {Test loss}=71.14264678955078\n",
            "2022-03-23 09:21:35,795 [nnabla][INFO]: iter=47399 {Elapsed time}=2.4238996505737305[sec/600iter] 193.3632845878601[sec]\n",
            "2022-03-23 09:21:38,216 [nnabla][INFO]: iter=47999 {Training loss}=78.32316589355469\n",
            "2022-03-23 09:21:38,217 [nnabla][INFO]: iter=47999 {Test loss}=71.2026138305664\n",
            "2022-03-23 09:21:38,217 [nnabla][INFO]: iter=47999 {Elapsed time}=2.421889305114746[sec/600iter] 195.78517389297485[sec]\n",
            "2022-03-23 09:21:40,644 [nnabla][INFO]: iter=48599 {Training loss}=78.20993041992188\n",
            "2022-03-23 09:21:40,644 [nnabla][INFO]: iter=48599 {Test loss}=71.11275482177734\n",
            "2022-03-23 09:21:40,644 [nnabla][INFO]: iter=48599 {Elapsed time}=2.427424430847168[sec/600iter] 198.21259832382202[sec]\n",
            "2022-03-23 09:21:43,083 [nnabla][INFO]: iter=49199 {Training loss}=78.12306213378906\n",
            "2022-03-23 09:21:43,084 [nnabla][INFO]: iter=49199 {Test loss}=71.08307647705078\n",
            "2022-03-23 09:21:43,084 [nnabla][INFO]: iter=49199 {Elapsed time}=2.4400436878204346[sec/600iter] 200.65264201164246[sec]\n",
            "2022-03-23 09:21:45,505 [nnabla][INFO]: iter=49799 {Training loss}=78.08972930908203\n",
            "2022-03-23 09:21:45,505 [nnabla][INFO]: iter=49799 {Test loss}=71.09549713134766\n",
            "2022-03-23 09:21:45,506 [nnabla][INFO]: iter=49799 {Elapsed time}=2.4211363792419434[sec/600iter] 203.0737783908844[sec]\n",
            "2022-03-23 09:21:47,934 [nnabla][INFO]: iter=50399 {Training loss}=78.02345275878906\n",
            "2022-03-23 09:21:47,935 [nnabla][INFO]: iter=50399 {Test loss}=71.05857849121094\n",
            "2022-03-23 09:21:47,935 [nnabla][INFO]: iter=50399 {Elapsed time}=2.4298524856567383[sec/600iter] 205.50363087654114[sec]\n",
            "2022-03-23 09:21:50,362 [nnabla][INFO]: iter=50999 {Training loss}=77.93182373046875\n",
            "2022-03-23 09:21:50,363 [nnabla][INFO]: iter=50999 {Test loss}=71.05155181884766\n",
            "2022-03-23 09:21:50,363 [nnabla][INFO]: iter=50999 {Elapsed time}=2.4278411865234375[sec/600iter] 207.93147206306458[sec]\n",
            "2022-03-23 09:21:52,784 [nnabla][INFO]: iter=51599 {Training loss}=77.8851318359375\n",
            "2022-03-23 09:21:52,785 [nnabla][INFO]: iter=51599 {Test loss}=71.00898742675781\n",
            "2022-03-23 09:21:52,785 [nnabla][INFO]: iter=51599 {Elapsed time}=2.4222309589385986[sec/600iter] 210.35370302200317[sec]\n",
            "2022-03-23 09:21:55,223 [nnabla][INFO]: iter=52199 {Training loss}=77.82527160644531\n",
            "2022-03-23 09:21:55,224 [nnabla][INFO]: iter=52199 {Test loss}=71.0113754272461\n",
            "2022-03-23 09:21:55,224 [nnabla][INFO]: iter=52199 {Elapsed time}=2.438899278640747[sec/600iter] 212.79260230064392[sec]\n",
            "2022-03-23 09:21:57,649 [nnabla][INFO]: iter=52799 {Training loss}=77.72169494628906\n",
            "2022-03-23 09:21:57,649 [nnabla][INFO]: iter=52799 {Test loss}=70.93211364746094\n",
            "2022-03-23 09:21:57,649 [nnabla][INFO]: iter=52799 {Elapsed time}=2.425053119659424[sec/600iter] 215.21765542030334[sec]\n",
            "2022-03-23 09:22:00,066 [nnabla][INFO]: iter=53399 {Training loss}=77.68461608886719\n",
            "2022-03-23 09:22:00,066 [nnabla][INFO]: iter=53399 {Test loss}=70.93928527832031\n",
            "2022-03-23 09:22:00,067 [nnabla][INFO]: iter=53399 {Elapsed time}=2.417128086090088[sec/600iter] 217.63478350639343[sec]\n",
            "2022-03-23 09:22:02,490 [nnabla][INFO]: iter=53999 {Training loss}=77.65067291259766\n",
            "2022-03-23 09:22:02,490 [nnabla][INFO]: iter=53999 {Test loss}=70.94070434570312\n",
            "2022-03-23 09:22:02,491 [nnabla][INFO]: iter=53999 {Elapsed time}=2.4240639209747314[sec/600iter] 220.05884742736816[sec]\n",
            "2022-03-23 09:22:04,899 [nnabla][INFO]: iter=54599 {Training loss}=77.60075378417969\n",
            "2022-03-23 09:22:04,900 [nnabla][INFO]: iter=54599 {Test loss}=70.93016815185547\n",
            "2022-03-23 09:22:04,900 [nnabla][INFO]: iter=54599 {Elapsed time}=2.4096245765686035[sec/600iter] 222.46847200393677[sec]\n",
            "2022-03-23 09:22:07,324 [nnabla][INFO]: iter=55199 {Training loss}=77.5815658569336\n",
            "2022-03-23 09:22:07,325 [nnabla][INFO]: iter=55199 {Test loss}=70.96697998046875\n",
            "2022-03-23 09:22:07,325 [nnabla][INFO]: iter=55199 {Elapsed time}=2.425095796585083[sec/600iter] 224.89356780052185[sec]\n",
            "2022-03-23 09:22:09,741 [nnabla][INFO]: iter=55799 {Training loss}=77.45899963378906\n",
            "2022-03-23 09:22:09,742 [nnabla][INFO]: iter=55799 {Test loss}=70.88758087158203\n",
            "2022-03-23 09:22:09,742 [nnabla][INFO]: iter=55799 {Elapsed time}=2.416989803314209[sec/600iter] 227.31055760383606[sec]\n",
            "2022-03-23 09:22:12,167 [nnabla][INFO]: iter=56399 {Training loss}=77.40386962890625\n",
            "2022-03-23 09:22:12,168 [nnabla][INFO]: iter=56399 {Test loss}=70.86570739746094\n",
            "2022-03-23 09:22:12,168 [nnabla][INFO]: iter=56399 {Elapsed time}=2.4255340099334717[sec/600iter] 229.73609161376953[sec]\n",
            "2022-03-23 09:22:14,589 [nnabla][INFO]: iter=56999 {Training loss}=77.36506652832031\n",
            "2022-03-23 09:22:14,589 [nnabla][INFO]: iter=56999 {Test loss}=70.90206146240234\n",
            "2022-03-23 09:22:14,589 [nnabla][INFO]: iter=56999 {Elapsed time}=2.4215426445007324[sec/600iter] 232.15763425827026[sec]\n",
            "2022-03-23 09:22:17,014 [nnabla][INFO]: iter=57599 {Training loss}=77.34807586669922\n",
            "2022-03-23 09:22:17,014 [nnabla][INFO]: iter=57599 {Test loss}=70.86547088623047\n",
            "2022-03-23 09:22:17,015 [nnabla][INFO]: iter=57599 {Elapsed time}=2.425262689590454[sec/600iter] 234.58289694786072[sec]\n",
            "2022-03-23 09:22:19,430 [nnabla][INFO]: iter=58199 {Training loss}=77.26326751708984\n",
            "2022-03-23 09:22:19,431 [nnabla][INFO]: iter=58199 {Test loss}=70.8437728881836\n",
            "2022-03-23 09:22:19,431 [nnabla][INFO]: iter=58199 {Elapsed time}=2.4167182445526123[sec/600iter] 236.99961519241333[sec]\n",
            "2022-03-23 09:22:21,852 [nnabla][INFO]: iter=58799 {Training loss}=77.19355773925781\n",
            "2022-03-23 09:22:21,853 [nnabla][INFO]: iter=58799 {Test loss}=70.84314727783203\n",
            "2022-03-23 09:22:21,853 [nnabla][INFO]: iter=58799 {Elapsed time}=2.4213449954986572[sec/600iter] 239.420960187912[sec]\n",
            "2022-03-23 09:22:24,278 [nnabla][INFO]: iter=59399 {Training loss}=77.14884185791016\n",
            "2022-03-23 09:22:24,278 [nnabla][INFO]: iter=59399 {Test loss}=70.81798553466797\n",
            "2022-03-23 09:22:24,279 [nnabla][INFO]: iter=59399 {Elapsed time}=2.425788402557373[sec/600iter] 241.84674859046936[sec]\n",
            "2022-03-23 09:22:26,712 [nnabla][INFO]: iter=59999 {Training loss}=77.10176849365234\n",
            "2022-03-23 09:22:26,712 [nnabla][INFO]: iter=59999 {Test loss}=70.81633758544922\n",
            "2022-03-23 09:22:26,712 [nnabla][INFO]: iter=59999 {Elapsed time}=2.4339687824249268[sec/600iter] 244.2807173728943[sec]\n",
            "2022-03-23 09:22:26,735 [nnabla][INFO]: Parameter save (.h5): tmp.monitor.vae/params_060000.h5\n",
            "2022-03-23 09:22:26,746 [nnabla][INFO]: Saving tmp.monitor.vae/lenet_result.nnp as nnp\n",
            "2022-03-23 09:22:26,746 [nnabla][INFO]: Saving <_io.StringIO object at 0x7fecc6c6ea50> as prototxt\n",
            "2022-03-23 09:22:26,858 [nnabla][INFO]: Parameter save (.protobuf): <_io.BytesIO object at 0x7fec8d6335f0>\n",
            "2022-03-23 09:22:26,868 [nnabla][INFO]: Model file is saved as (.nnp): tmp.monitor.vae/lenet_result.nnp\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 学習結果を Google Drive に保存"
      ],
      "metadata": {
        "id": "eymmH0pCc-TJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!cd drive/MyDrive && if [ ! -d my-vae-nnabla ]; then mkdir my-vae-nnabla; fi\n",
        "!cd drive/MyDrive/my-vae-nnabla && if [ -d step1 ]; then rm -rf step1; fi\n",
        "!cp -r nnabla-examples/image-classification/mnist-collection/tmp.monitor.vae drive/MyDrive/my-vae-nnabla/step1"
      ],
      "metadata": {
        "id": "1S-YvH4idCjS"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Google Drive に保存した学習結果は、Step 2 で使用します。"
      ],
      "metadata": {
        "id": "rBrAUFQ-kiWW"
      }
    }
  ]
}