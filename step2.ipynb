{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "step2.ipynb",
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyP5iTl3dTzVg+e6B66BrK68",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hrnrhty/my-vae-nnabla/blob/main/step2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 2 - 入力画像と VAE 生成画像の比較"
      ],
      "metadata": {
        "id": "g5UPM5tcgQaR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 2 では、Step 1 で学習した結果を用いて VAE (Variational Auto Encoder) の推論を実行します。VAE で推論を実行すると画像が生成されます。生成された画像が入力画像と比較してどのように違うのか、実際に画像を表示して確認していきます。\n",
        "\n",
        "なお、このステップを実行するには Step 1 の学習結果が必須です。まだ Step 1 を実行していない場合は、先に Step 1 を最後まで実行して学習結果を準備してください。Step 1 のノートブックは以下のバナーから開くことができます。  \n",
        "[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/hrnrhty/my-vae-nnabla/blob/main/step1.ipynb)\n",
        "\n",
        "また、推論は学習に比べて処理に時間がかからないため、このステップでは GPU アクセラレーションを使用せず、CPU のみで処理を実行していきます。"
      ],
      "metadata": {
        "id": "kLbjAWQOgcly"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Google Drive のマウント"
      ],
      "metadata": {
        "id": "jWUNkz_fEGqX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 1 の学習結果を読み込むため Google Drive をマウントします。\n",
        "\n",
        "> Note: 先に Step 1 を最後まで実行しておいてください。"
      ],
      "metadata": {
        "id": "HR9qqGKkEJwE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "Ch7YlrHkETaW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## NNabla のインストール"
      ],
      "metadata": {
        "id": "R69qhfdOEyMt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "本ステップでは GPU アクセラレーションを使用しないので、通常の [NNabla](https://github.com/sony/nnabla) だけをインストールします（CUDA 版はインストールしません）。\n",
        "\n",
        "ここでは、2022 年 2 月 2 日時点、最新バージョンである v1.25.0 をインストールしますが、おもむろにインストールを実行すると `pip` コマンドの実行結果の中にエラーメッセージが表示されます。依存パッケージの中に、Google Colab のランタイムにはじめからインストールされているものがあり、そのバージョンが NNabla が要求するバージョンよりも新しいバージョンであることが原因です。\n",
        "\n",
        "エラーが表示されても NNabla のインストールに成功していれば以降のコードは問題なく実行できることがほとんどですが、ここでは NNabla が要求するバージョンのパッケージを手動インストールすることによりエラーを回避します。\n",
        "\n",
        "下記、1 行目のコマンドは NNabla の依存パッケージの一部をバージョン指定でインストールします。2 行目のコマンドは NNabla をインストールします。\n",
        "\n",
        "どのようなエラーメッセージが表示されるのか気になる方は、1 行目をコメントアウトして実行してみてください。一度実行済の場合は、Google Colab のランタイムを出荷設定にリセットしてから実行してください。"
      ],
      "metadata": {
        "id": "u0ZSHp1CE1IB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install urllib3==1.25.11 folium==0.2.1\n",
        "!pip install nnabla==1.25.0"
      ],
      "metadata": {
        "id": "T8owuSM9E-oa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## nnabla-examples のクローン"
      ],
      "metadata": {
        "id": "vtQX_8CyFBwx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 1 同様、[nnabla-examples](https://github.com/sony/nnabla-examples) v1.25.0 をクローンします。"
      ],
      "metadata": {
        "id": "bldRIhisFFpa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!if [ -d nnabla-examples ]; then rm -rf nnabla-examples; fi\n",
        "!git clone https://github.com/sony/nnabla-examples.git -b v1.25.0 --depth 1"
      ],
      "metadata": {
        "id": "4e_3VC_OF10c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## VAE 関数の読み込み"
      ],
      "metadata": {
        "id": "hlVPH1TgF6zK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "[nnabla-examples](https://github.com/sony/nnabla-examples) の `vae.py` およびその他 Helper 関数を利用するため、カレントディレクトリを移動します。"
      ],
      "metadata": {
        "id": "kkSYdoQ6zXuJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd 'nnabla-examples/image-classification/mnist-collection'"
      ],
      "metadata": {
        "id": "saXZgcYSHyGE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "`vae.py` 内で提供されている関数 `vae` は `loss` しか返しません。そこで、推論結果も返すように `vae.py` を書き換えます。"
      ],
      "metadata": {
        "id": "mUCVHznf0LtA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!sed -i -e 's/return loss/return loss, prob/g' vae.py"
      ],
      "metadata": {
        "id": "VZgGAbGBSWb9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "推論結果 `prob` も返すように改造した関数 `vae` をインポートします。"
      ],
      "metadata": {
        "id": "aPJ1kkqc0axS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from vae import vae"
      ],
      "metadata": {
        "id": "_kYhOA_-I7nh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 学習結果の読み込み"
      ],
      "metadata": {
        "id": "TwMBF3Zw0pY0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "後ほど使用する module も含め、ここでまとめてインポートします。"
      ],
      "metadata": {
        "id": "Fl3ViqHG0u2_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nnabla as nn\n",
        "import nnabla.functions as F\n",
        "from mnist_data import data_iterator_mnist"
      ],
      "metadata": {
        "id": "j5B12gg5JF3f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 1 で保存した学習済みパラメータを読み込みます。"
      ],
      "metadata": {
        "id": "tOzlGo6b05Te"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "_ = nn.load_parameters('/content/drive/MyDrive/my-vae-nnabla/step1/params_060000.h5')"
      ],
      "metadata": {
        "id": "hbX_S6AOJqoo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 推論の実行"
      ],
      "metadata": {
        "id": "Kv8HbHxI1BxV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "学習済モデルが準備できたので、推論を実行してみます。下記のコードでは、変数 `x` を作成し、[MNIST](http://yann.lecun.com/exdb/mnist/) データセットからランダムに10個の画像を取り出し、`x` に格納しています。そして、関数 `vae` の推論結果に `sigmoid` 関数を適用してデータの値域を (0, 1.0) の区間に正規化し、最終的な推論結果とするよう定義しています。最後の行で `forward()` をコールし、推論を実行しています。"
      ],
      "metadata": {
        "id": "wiurbUgJ1OlQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "shape_x = (1, 28, 28)\n",
        "shape_z = (50,)\n",
        "x = nn.Variable((10,) + shape_x)\n",
        "\n",
        "loss, prob = vae(x, shape_z, test=True)\n",
        "di_t = data_iterator_mnist(10, False)\n",
        "x.d, _ = di_t.next()\n",
        "prob = F.sigmoid(prob)\n",
        "prob.forward()"
      ],
      "metadata": {
        "id": "CQOUSTMqKDMn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "GPU アクセラレーションは使用していませんが、あっという間に推論が完了しましたね。\n",
        "\n",
        "それでは、入力画像とそれに対応する推論結果（生成された画像）を表示してみましょう。ここでは、画像の表示に `matplotlib` を使用します。"
      ],
      "metadata": {
        "id": "kgR2Ad6M3Ibr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "z6nuXul1KEJp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "8 枚目（index = 7）の入力画像を表示してみます。\n",
        "\n",
        "ここで、入力画像の値域は [0, 255] になっています。このままでも画像の表示はできますが、あとで生成画像と比較するため 256 で割って [0, 1) の区間に正規化します。"
      ],
      "metadata": {
        "id": "ZHKqmocN47A0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "img_num = 7"
      ],
      "metadata": {
        "id": "u56nESCX5StQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_img = x.d[img_num][0] / 256.\n",
        "print('---- 入力画像 ----')\n",
        "print('Min. value =', input_img.min())\n",
        "print('Max. value =', input_img.max())\n",
        "plt.imshow(input_img, cmap='gray')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "7mgCoByy3fbt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "続いて、推論の結果、VAE が生成した画像を表示してみます。"
      ],
      "metadata": {
        "id": "fVNzZ8k-5iU_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "output_img = prob.d[img_num][0]\n",
        "print('---- VAE 生成画像 ----')\n",
        "print('Min. value =', output_img.min())\n",
        "print('Max. value =', output_img.max())\n",
        "plt.imshow(output_img, cmap='gray')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "iEI4oEup41zC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "ちゃんと \"2\" と判別ができる画像が生成されています！しかしよく見ると、入力画像とは少し異なる点もあるようです。\n",
        "\n",
        "様々な手書き数字を学習した VAE は、平均的な \"2\" の生成を試みるようにトレーニングされています。そのため、入力画像に見られた上部の黒い点が消えたり、下部の線の湾曲が直線に近づいたり、全体的に滑らかになった印象があります。"
      ],
      "metadata": {
        "id": "6xPzTP0554zC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "それでは最後に、入力画像と生成画像の差の絶対値をヒートマップ化して、入力画像の上に重ねて表示してみましょう。"
      ],
      "metadata": {
        "id": "wEEpFvEz7EmE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "diff = output_img - input_img\n",
        "abs_diff = abs(diff)\n",
        "score = sum(sum(abs_diff))\n",
        "print('---- 入力画像に VAE 生成画像との差分を重畳 ----')\n",
        "print('Sum of absolute values of difference =', score)\n",
        "print('Min. diff. (abs) =', abs_diff.min())\n",
        "print('Max. diff. (abs) =', abs_diff.max())\n",
        "plt.imshow(input_img, cmap='gray')\n",
        "diff_img = plt.imshow(abs_diff, cmap='jet', alpha=0.5)\n",
        "plt.colorbar(diff_img)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "3GGG7ZlDT3ow"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "他の数字も同様に確認してみましょう。"
      ],
      "metadata": {
        "id": "m1G2FuuU-KZl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "img_num = 8"
      ],
      "metadata": {
        "id": "rXWtrodH-OJb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_img = x.d[img_num][0] / 256.\n",
        "print('---- 入力画像 ----')\n",
        "print('Min. value =', input_img.min())\n",
        "print('Max. value =', input_img.max())\n",
        "plt.imshow(input_img, cmap='gray')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "MBAdl1eN_4_8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output_img = prob.d[img_num][0]\n",
        "print('---- VAE 生成画像 ----')\n",
        "print('Min. value =', output_img.min())\n",
        "print('Max. value =', output_img.max())\n",
        "plt.imshow(output_img, cmap='gray')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ie9Wljee-jl4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "diff = output_img - input_img\n",
        "abs_diff = abs(diff)\n",
        "score = sum(sum(abs_diff))\n",
        "print('---- 入力画像に VAE 生成画像との差分を重畳 ----')\n",
        "print('Sum of absolute values of difference =', score)\n",
        "print('Min. diff. (abs) =', abs_diff.min())\n",
        "print('Max. diff. (abs) =', abs_diff.max())\n",
        "plt.imshow(input_img, cmap='gray')\n",
        "diff_img = plt.imshow(abs_diff, cmap='jet', alpha=0.5)\n",
        "plt.colorbar(diff_img)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "5tRZkHzN-kKy"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}